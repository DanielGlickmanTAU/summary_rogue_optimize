


todo:
1)repeat experiment 3 times with different training sets:
may be easy to do in data_loading.convert_to_generation_training:
            dataset_split = dataset_split.select(range(2 * max_samples)) <-- change this to select 1k
            ...
            ...
            if max_samples:
                 ** here shuffle before select
                dataset_split = dataset_split.select(range(max_samples))



may be problems:
training on cnn is not consistent

extra:
BCELoss weights(higher for positives)(can do it by adding positve at start of labels and giving it higher weight)

in repeat, can either train the whole model(filter) from scratch, or continue. use --overwrite output dir for that