train filter:
* when combing filter back, be mindful to seperate filter and generator learning rates
notice train rouge is much higher than vaclidaiton.. switch validation and train set? or give each one 128, from validation
* train filter with generated dataset loading, so cna test hyper params faster..



cross entropy
waserstien


get baseline results for [1,--256]..
continue further research only on values for which rouge2 increase with oracle selection(32,64,128)







to run:
more baselines on xsum and cnn...(see what baselines are missing)


may be problems:
training on cnn is not consistent

extra:
BCELoss weights(higher for positives)(can do it by adding positve at start of labels and giving it higher weight)

in repeat, can either train the whole model(filter) from scratch, or continue. use --overwrite output dir for that

considertion:
max seq len(bert), text+summary

training on validation