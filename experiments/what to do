so run_summerization.py is working and determenistic.. with 1k examples gets 'eval_rouge2': 10.3939 on 64 examples


todo:
early stopping..by rouge2.. or save best metric rouge2
average 5 runs to see consistant results... random training examples

try if add_summary_and_rouge works
    create summaries on validation and development set.. and also on train for training ranker




train on samples generated on validation; not test..




algorithm limitations:
max length is 512
validation=train
n_beams = 2

implementation limitations:
more than 1 batch
more than 1 gpu



different loss
In Progess:
replace list[num_beams][input_ids_tensor] into tensor of shape(num_beams,input_ids_tensor) // use torch.stack.. in collator i think

if labels are equal, skip loss


class roberaranker(roberaForrSEQClassification): with predict select top method


    4) carefully debug the input into the network
    5) overfit 100 examples on regression





ranker : normalize outputs? per sample?(regression)

try:
    try regular fine tuning..overfit


DONE:
test that not all attention_mask is 1, some should be zero for padding




fix issues with long articles...
I can pospone full length for now..
^ change no_repeat_ngram_size to 3?

tried:
    select always above average

    append to input text "summarize: " | DOESNT WORK

    force_bos_token_to_be_generated=False | DOESNT MATTER
